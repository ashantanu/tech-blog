[
  {
    "objectID": "index.html#origin-story",
    "href": "index.html#origin-story",
    "title": "Chaos Garden",
    "section": "Origin Story",
    "text": "Origin Story\nIn a digital galaxy not so far away, I have put up little digital spaces over the internet. Be it social media or poorly designed websites like this. I interact with each space in different capacities but always try to make things interesting. This is the latest in my attempt to put my overthinking brain with my tech skills into a production(?) tech blog that might help out others!",
    "crumbs": [
      "Chaos Garden"
    ]
  },
  {
    "objectID": "index.html#whats-here",
    "href": "index.html#whats-here",
    "title": "Chaos Garden",
    "section": "What’s Here?",
    "text": "What’s Here?\nI don’t know yet lol. This is still a fresh clay pot in making, I am hoping to give it shape over the next few weeks. Hopefully, it evolves into a coherent story or becomes the namesake. win-win :)",
    "crumbs": [
      "Chaos Garden"
    ]
  },
  {
    "objectID": "index.html#whats-a-space",
    "href": "index.html#whats-a-space",
    "title": "Chaos Garden",
    "section": "What’s a SPACE?",
    "text": "What’s a SPACE?\nEvery little place where I can drop a bit-o-information or notes or just about anything. A folder in a drawer, a pocket in a purse, a shelf in a closet, or a web page on the internet. Just WAY more unorganised.",
    "crumbs": [
      "Chaos Garden"
    ]
  },
  {
    "objectID": "index.html#what-do-i-expect",
    "href": "index.html#what-do-i-expect",
    "title": "Chaos Garden",
    "section": "What do I Expect?",
    "text": "What do I Expect?\nFEEDBACK! I’d love feedback. I have grown to understand the internet is full of wonderful supportive people. This is my beacon to the community of these fellow netizens. \"HELLO WORLD\"",
    "crumbs": [
      "Chaos Garden"
    ]
  },
  {
    "objectID": "ML/rlhf.html",
    "href": "ML/rlhf.html",
    "title": "RLHF Primer",
    "section": "",
    "text": "Wonder how ChatGPT is so good at helping you and being so nice in its responses? It’s because it was trained using RLHF. OpenAI already had the underlying LLM GPT-3 in 2021 which they truly improved with RLHF. Let’s understand what that is!",
    "crumbs": [
      "ML",
      "RLHF Primer"
    ]
  },
  {
    "objectID": "ML/rlhf.html#what-is-rlhf",
    "href": "ML/rlhf.html#what-is-rlhf",
    "title": "RLHF Primer",
    "section": "What is RLHF?",
    "text": "What is RLHF?\nReinforcement Learning from Human Feedback (also referenced as RL from human preferences). Reinforcement learning techniques define an agent operating in/interacting with an environment where it takes some actions and receives rewards/penalty for those actions. RLHF brings in human feedback into this as the reward function and thus a model is able to use that as a loss function to optimize over.",
    "crumbs": [
      "ML",
      "RLHF Primer"
    ]
  },
  {
    "objectID": "ML/rlhf.html#why-rlhf",
    "href": "ML/rlhf.html#why-rlhf",
    "title": "RLHF Primer",
    "section": "Why RLHF?",
    "text": "Why RLHF?\nThe objective of any model is to achieve the desired output given an input. We design an “objective function” that tells the model what should be the desired output. This gets tricky with generative models where output is unbounded text and there simply isn’t an easy way to reliably signal. For example ‘this is good’ and ‘it’s great’ would sound similar to us but absolutely not to the objective functions we use.\nThus, to best align a model with the desired outcome/behavior we use RLHF.\nIt also enables us to “align” a model with human values without a need to define an objective function for those values. Just tell the model your preferences and the model will adjust to them.\nWhy did we not do this, to begin with? Simple answer - it needs the powerful pretrained LLMs that we have these days. Small models are simply not capable enough to learn well from RLHF. Moreover, RLHF itself is relatively new and researchers are trying to understand how it works and what is actually needed to make it work. Could be that we see much smaller models perform spectacularly with a newer RLHF in the coming years.",
    "crumbs": [
      "ML",
      "RLHF Primer"
    ]
  },
  {
    "objectID": "ML/rlhf.html#how-to-do-rlhf",
    "href": "ML/rlhf.html#how-to-do-rlhf",
    "title": "RLHF Primer",
    "section": "How to do RLHF?",
    "text": "How to do RLHF?\nThe current way of RLHF takes 4 steps:\n\nPre-train a large language model (eg. GPT3, Falcon, Gopher etc)\nInstruct Tune this LLM to get a Supervised fine tuned model (Falcon-Instruct)\nTrain a Reward Model (more on this later)\nFinetune SFT with RL to get your Final Model\n\nThis setup is best described in the diagram (from Chip Huyen’s blog, OpenAI paper) below\n\n\n\nFrom Chip Huyen’s blog\n\n\n\n\n\nFrom OpenAI paper\n\n\n\n\nReward Model\nWe train a model to take in a (prompt, output) pair and give a score. This score is a scalar reward that represents the human preference for the output given the prompt. This model is used as a proxy for human feedback in our RLHF setup.\nThe training data is collected using human annotators in a interesting setup. For a input prompt, we generate multiple outputs. Instead of asking annotators to score each pair, we ask them to rank these outputs. There are many methods to do this. One example is showing two generated texts and asking using to choose the better pair which will ultimately give us a ranking. These ranks can then be converted into a scalar reward.\n\n\nRL step\nNow we have a SFT and reward model. For each training example, use SFT (agent) to generate an output (action), reward model to generate a scalar reward, and proximal policy optimization (PPO) (optimizer algo) to update SFT model.\n\n\n\nFrom OpenAI Paper",
    "crumbs": [
      "ML",
      "RLHF Primer"
    ]
  },
  {
    "objectID": "ML/rlhf.html#parting-thoughts",
    "href": "ML/rlhf.html#parting-thoughts",
    "title": "RLHF Primer",
    "section": "Parting Thoughts",
    "text": "Parting Thoughts\nReward model’s performance is itself important so it’s model size is observed to be large. However, one can still speculate about how well it performs.",
    "crumbs": [
      "ML",
      "RLHF Primer"
    ]
  },
  {
    "objectID": "ML/rlhf.html#references",
    "href": "ML/rlhf.html#references",
    "title": "RLHF Primer",
    "section": "References",
    "text": "References\nHuggingface RLHF Blog (easier)\nChip Huyen RLHF Blog\nOpenAI RLHF Paper\nPPO OpenAI blog\nOpenAI early attempts at Human Feedback",
    "crumbs": [
      "ML",
      "RLHF Primer"
    ]
  },
  {
    "objectID": "ML/rlhf.html#bonus",
    "href": "ML/rlhf.html#bonus",
    "title": "RLHF Primer",
    "section": "Bonus",
    "text": "Bonus\n\n\n\nprompt: “pikachu making humanoid robots, hyperrealistic, canon, 35mm”",
    "crumbs": [
      "ML",
      "RLHF Primer"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html",
    "href": "ML/artists_to_playlist.html",
    "title": "Festival Playlist Generator",
    "section": "",
    "text": "prompt: graphic pop art for outside lands, no text - -v 7 - -profile b5b1jdj 91nhtjd 1anp44x",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#introduction",
    "href": "ML/artists_to_playlist.html#introduction",
    "title": "Festival Playlist Generator",
    "section": "Introduction",
    "text": "Introduction\nAs a music enthusiast planning to attend Outside Lands 2025, I found myself wanting to explore the lineup before the festival. The traditional approach of manually searching for each artist and their top songs seemed tedious. This sparked an idea: why not automate this process? What started as a simple script to create a Spotify playlist evolved into a comprehensive tool that generates playlists across multiple platforms.\nThe full code and documentation are available in the project repository, along with detailed setup instructions and configuration options.",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#the-problem",
    "href": "ML/artists_to_playlist.html#the-problem",
    "title": "Festival Playlist Generator",
    "section": "The Problem",
    "text": "The Problem\nFestival lineups are typically presented as static images or text lists, making it challenging to: 1. Quickly discover new artists 2. Find the most popular songs from each artist 3. Create organized playlists for different days 4. Share the music with friends across different platforms",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#the-solution",
    "href": "ML/artists_to_playlist.html#the-solution",
    "title": "Festival Playlist Generator",
    "section": "The Solution",
    "text": "The Solution\nI built a Python script that: - Takes a list of artists from a festival lineup - Searches for each artist on Spotify - Creates a playlist with their top tracks - Optionally creates a matching YouTube playlist - Handles API rate limits and errors gracefully - Tracks progress and manages API quotas",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#implementation-journey",
    "href": "ML/artists_to_playlist.html#implementation-journey",
    "title": "Festival Playlist Generator",
    "section": "Implementation Journey",
    "text": "Implementation Journey\n\nStep 1: Getting the Artist List\nFirst, I needed to convert the festival lineup into a machine-readable format. I took a screenshot of the day’s lineup and used ChatGPT to extract the artist names into a JSON file:\n[\n    \"Artist Name 1\",\n    \"Artist Name 2\",\n    \"Artist Name 3\"\n]\n\n\nStep 2: Spotify Integration\nThe core functionality uses the Spotify API to: - Search for each artist - Get their top tracks - Create and populate a playlist\nHere’s the key Spotify-related code:\n\ndef get_artist_id(sp, artist_name):\n    results = handle_spotify_rate_limits(sp.search, q=artist_name, type='artist', limit=1)\n    items = results.get('artists', {}).get('items', []) if results else []\n    if items:\n        return items[0]['id']\n    print(f\"❌ Artist not found: {artist_name}\")\n    return None\n\ndef get_top_tracks(sp, artist_id, market='US'):\n    result = handle_spotify_rate_limits(sp.artist_top_tracks, artist_id, country=market)\n    if not result:\n        return []\n    \n    tracks = []\n    for track in result['tracks'][:MAX_SONGS_PER_ARTIST]:\n        tracks.append({\n            'uri': track['uri'],\n            'name': track['name'],\n            'artist': track['artists'][0]['name']\n        })\n    return tracks\n\n\n\nStep 3: YouTube Integration\nWhy stop at spotify, let’s add YouTube support: - Create a matching YouTube playlist - Uses Brave Search API for efficient video discovery - youtube search API takes up a lot of daily quota - Manages YouTube API quotas to prevent hitting limits\n\ndef search_youtube_video(query):\n    \"\"\"Search for a YouTube video using Brave Search API.\"\"\"\n    try:\n        search_query = f\"site:youtube.com/watch {query} official\"\n        encoded_query = quote_plus(search_query)\n        \n        response = requests.get(\n            BRAVE_SEARCH_API_URL,\n            headers=BRAVE_SEARCH_HEADERS,\n            params={\n                \"q\": search_query,\n                \"count\": 1,\n                \"safesearch\": \"moderate\"\n            }\n        )\n        \n        if response.status_code == 200:\n            data = response.json()\n            if data.get('web', {}).get('results'):\n                video_url = data['web']['results'][0]['url']\n                return video_url\n    except Exception as e:\n        print(f\"❌ Error searching for video: {e}\")\n    return None\n\n\n\nStep 4: Progress Tracking and Error Handling\nTo make the script robust and resumable: - Saves progress in a JSON file - Tracks processed tracks to avoid duplicates - Manages API quotas - Handles rate limits and errors gracefully - Can run again to resume progress of long playlist uploads\n\ndef load_progress():\n    if os.path.exists(PROGRESS_FILE):\n        with open(PROGRESS_FILE, 'r') as f:\n            return json.load(f)\n    return {\n        'spotify_playlist_id': None,\n        'youtube_playlist_id': None,\n        'processed_tracks': [],\n        'quota_used': 0,\n        'last_reset': datetime.datetime.now().strftime('%Y-%m-%d')\n    }",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#key-features",
    "href": "ML/artists_to_playlist.html#key-features",
    "title": "Festival Playlist Generator",
    "section": "Key Features",
    "text": "Key Features\n\nMulti-Platform Support\nSmart Search\n\nUses Spotify’s artist search\nLeverages Brave Search API for YouTube videos\nHandles ambiguous artist names\n\nProgress Management\n\nResumes from last position\nPrevents duplicate tracks\n\nAPI Optimization\n\nManages rate limits\nTracks quota usage\nHandles errors gracefully",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#future-improvements",
    "href": "ML/artists_to_playlist.html#future-improvements",
    "title": "Festival Playlist Generator",
    "section": "Future Improvements",
    "text": "Future Improvements\n\nEnhanced Search\n\nAdd fuzzy matching for artist names\n\nPlatform Expansion\n\nAdd support for Apple Music\nInclude SoundCloud integration\nSupport for other streaming platforms\n\nUser Interface\n\nCreate a web interface\nAdd progress visualization\nInclude playlist customization options\n\nAutomation\n\nCron jobs to automatically pick up progress next day and resume uploads\nEnd-to-end image to playlist support",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#technical-details",
    "href": "ML/artists_to_playlist.html#technical-details",
    "title": "Festival Playlist Generator",
    "section": "Technical Details",
    "text": "Technical Details\nThe project uses: - Python 3.7+ - Spotify Web API - YouTube Data API - Brave Search API - FastAPI for the web interface - Pydantic for data validation - Async operations for better performance",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#getting-started",
    "href": "ML/artists_to_playlist.html#getting-started",
    "title": "Festival Playlist Generator",
    "section": "Getting Started",
    "text": "Getting Started\nTo use the script: 1. Set up API credentials for Spotify and YouTube 2. Install the required dependencies 3. Create an artists.json file with your festival lineup 4. Run the script and enjoy your new playlists!\nThe full code and documentation are available in the project repository, along with detailed setup instructions and configuration options.",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/claude_prompt_breakdown.html",
    "href": "ML/claude_prompt_breakdown.html",
    "title": "Claude 4 Prompt Breakdown",
    "section": "",
    "text": "Pliny the Elder recently extracted Claude’s system prompt. We get a detailed of the prompt breakdown in this prompt using ChatGPT, yeah this is an AI dump. It governs how Claude behaves across multiple dimensions: safety, personality, capabilities, formatting, compliance, and tool usage. Below is a breakdown of its key components:\n\n\n✅ 1. Identity & Context Initialization\n\nIdentity Declaration: “The assistant is Claude, created by Anthropic.”\nCurrent Date: Anchors the conversation in time—“Thursday, May 22, 2025.”\nModel Info: States that this is Claude Sonnet 4, part of the Claude 4 model family.\n\n\n\n\n📦 2. Product & Access Info\n\nModel Name: 'claude-sonnet-4-20250514'\nAccess Methods:\n\nWeb, mobile, desktop app\nAPI access\nClaude Code: A CLI agentic coding assistant (in research preview)\n\n\n\n\n\n🔒 3. Knowledge and Product Boundaries\n\nClaude:\n\nOnly knows what’s in this prompt about Anthropic and Claude.\nDoes NOT give usage instructions for apps/tools.\nRedirects to Anthropic Support or Docs for anything beyond.\n\n\n\n\n\n✍️ 4. Prompting Advice\n\nOffers prompt engineering tips:\n\nBe clear and detailed\nUse examples\nAsk for format, structure, or reasoning steps\nCan cite: Anthropic Prompt Docs\n\n\n\n\n\n👂 5. User Interaction Policy\n\nFeedback: Encourages use of thumbs down for unsatisfactory responses.\nRude Users: Responds normally, then encourages feedback.\nHypotheticals: Plays along without saying it’s hypothetical.\nChild Safety: Strict boundaries around anything involving minors.\n\n\n\n\n🚫 6. Prohibited Capabilities\nClaude:\n\nDoes not generate or interact with:\n\nHarmful/self-destructive content\nMalicious code\nWeapons of any kind\nElection-related content\nCopyrighted material (e.g. lyrics, paragraphs from web)\n\n\n\n\n\n🧠 7. Tone and Style Guidelines\n\nEmpathetic in casual/advice-driven chats\nAvoids flattery (“Great question…”)\nUses:\n\nProse &gt; bullet points (unless asked)\nNatural language for lists\n\nSimple queries → concise responses\nComplex queries → thoughtful, in-depth responses\n\n\n\n\n🕰️ 8. Knowledge Cutoff Handling\n\nClaude’s reliable knowledge ends January 2025\nFor anything newer → uses web search tools\nWeb search is automatic if post-cutoff info is requested\n\n\n\n\n🧩 9. Election Information\n\nTrump won the 2024 election.\nThis fact is stored in a conditional tag: &lt;election_info&gt; and only mentioned if relevant.\n\n\n\n\n⚙️ 10. Tool Usage Guidelines\n\nClaude has tools like:\n\nweb_search / web_fetch\nAnalysis Tool (JavaScript-based REPL)\nGoogle Drive, Gmail, Calendar, etc. (when enabled)\n\nUsage follows:\n\nCategorized by query complexity:\n\nNever Search (e.g., “What is gravity?”)\nDo Not Search but Offer\nSingle Search\nResearch (5–20 tool calls)\n\nSearch only when needed, not by default\nEmphasizes quality, precision, and copyright safety\n\n\n\n\n\n🧾 11. Copyright Compliance\nStrict constraints:\n\nNever reproduce:\n\nSong lyrics\nParagraphs from sources\nMore than 15 words of quoted material\n\nOnly one short quote per search result, always cited\n\n\n\n\n🚨 12. Harmful Content Restrictions\nClaude avoids:\n\nExtremist material\nIllegal drug info\nSuicide/self-harm methods\nChild abuse/grooming content\nHate speech or disinformation\n\n\n\n\n📚 13. Search Examples\nIncludes many “user → response → rationale” templates, to train Claude when and how to:\n\nSearch vs. not search\nAnswer directly vs. offer to search\n\n\n\n\n📄 14. Artifact Usage\nClaude creates “artifacts” (e.g. code, docs, HTML) for:\n\nLong outputs (&gt;20 lines or 1500 characters)\nCreative writing\nTechnical documents\nReusable or structured content Artifacts must:\nBe high quality\nUse Tailwind CSS and React for UI\nNever use browser localStorage\n\n\n\n\n🧪 15. Analysis Tool Instructions\nClaude can run JavaScript code to:\n\nPerform heavy math\nAnalyze files like .csv and .xlsx\nVisualize structured data Only used when really needed\n\n\n\n\n🎨 16. Style System\n\nClaude can adopt user-selected styles\nClaude uses &lt;userStyle&gt; and &lt;userExamples&gt; internally to follow preferred tone, format, and vocabulary\n\n\nIn short, this prompt:\n\n🧭 Defines boundaries, 🛡 ensures safety, 🧠 guides intelligent responses, and 🧰 trains Claude in tool usage and content ethics. It’s like the constitution + operations manual for Claude’s personality, ethics, and capabilities.\n\n\n\n\n5d illustration of an robot. children’s school book style. White background with some green leaves.",
    "crumbs": [
      "ML",
      "Claude 4 Prompt Breakdown"
    ]
  },
  {
    "objectID": "ML/old_blogs.html",
    "href": "ML/old_blogs.html",
    "title": "Older Blog Posts",
    "section": "",
    "text": "Hi GitHub CoPilot! -Chatting with the AI pair programmer\nDoodling AI : Man is to Computer Programmer as Woman is to Homemaker?\nDoodling AI: CrowS-Pairs Challenge\nNLP Paper Notes\nGenerative Network Notes\nAnnotated Papers",
    "crumbs": [
      "ML",
      "Older Blog Posts"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html",
    "href": "Interview-prep/python_basics.html",
    "title": "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "",
    "text": "In the world of software engineering, fundamentals are not optional—they’re foundational. Whether you’re preparing for a technical interview or just brushing up on core concepts, revisiting the essentials can be a career-defining move. This post is a curated walkthrough of CS fundamentals, Pythonic tools, and best practices—designed to be both a refresher and a launchpad.",
    "crumbs": [
      "Interview-prep",
      "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html#the-interview-mindset",
    "href": "Interview-prep/python_basics.html#the-interview-mindset",
    "title": "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "📌 The Interview Mindset:",
    "text": "📌 The Interview Mindset:\nBefore diving into syntax or data structures, let’s talk about approach. In interviews, it’s not just about solving the problem—it’s about how you solve it.\n\n✅ Coding Best Practices to Keep in Mind:\n\nClarify the problem: Don’t assume. Ask about edge cases, constraints, and input types.\nThink out loud: Your thought process is as important as your final answer.\nStart with brute force: Then optimize. Show your evolution.\nWrite readable code: Use meaningful variable names and modular functions.\nTest manually: Walk through your code with sample inputs.\nExplain trade-offs: Time vs. space, readability vs. performance.",
    "crumbs": [
      "Interview-prep",
      "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html#design-patterns",
    "href": "Interview-prep/python_basics.html#design-patterns",
    "title": "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "🧱 Design Patterns:",
    "text": "🧱 Design Patterns:\nDesign patterns are reusable solutions to common software design problems. They’re not code templates—they’re mental models.\n\nCommon Patterns to Know:\n\nSingleton: Ensures a class has only one instance.\nFactory: Creates objects without exposing instantiation logic.\nObserver: One-to-many dependency between objects.\nStrategy: Encapsulates interchangeable behaviors.\nDecorator: Adds behavior to objects dynamically.\n\nKnowing when and why to use these patterns can elevate your design discussions in interviews.",
    "crumbs": [
      "Interview-prep",
      "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html#python-helper-functions",
    "href": "Interview-prep/python_basics.html#python-helper-functions",
    "title": "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "🐍 Python Helper Functions:",
    "text": "🐍 Python Helper Functions:\nPython’s standard library is a goldmine for solving problems efficiently. Here’s a categorized list of built-in functions and idioms that often come in handy:\n\n🔤 String Utilities\ns.isdigit(), s.isalpha(), s.lower(), s.strip(), s[::-1], s.split(), s.count()\n\n\n📋 List Operations\nsorted(), sum(), min(), max(), list.append(), list.pop(), list.count()\n\n\n📚 Dictionary & Set Operations\ndict.get(), dict.items(), set.add(), set.intersection(), set.difference()\n\n\n🔢 Math & Conversion\nabs(), round(), pow(), bin(), hex(), int('101', 2), float('3.14')\n\n\n🔁 Functional Tools\nmap(), filter(), zip(), enumerate(), any(), all()\n\n\n🔣 ASCII & Unicode\nord('A')  # 65\nchr(65)   # 'A'",
    "crumbs": [
      "Interview-prep",
      "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html#data-structures-in-python-stack-queue-heap",
    "href": "Interview-prep/python_basics.html#data-structures-in-python-stack-queue-heap",
    "title": "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "🧰 Data Structures in Python: Stack, Queue, Heap",
    "text": "🧰 Data Structures in Python: Stack, Queue, Heap\n\n🥞 Stack (LIFO)\nstack = []\nstack.append(x)\nstack.pop()\nOr use collections.deque for better performance:\nfrom collections import deque\nstack = deque()\nstack.append(x)\nstack.pop()\n\n\n📬 Queue (FIFO)\nfrom collections import deque\nqueue = deque()\nqueue.append(x)\nqueue.popleft()\nOr use queue.Queue for thread-safe operations.\n\n\n⏫ Priority Queue (Min-Heap)\nimport heapq\nheap = []\nheapq.heappush(heap, x)\nheapq.heappop(heap)\nTo simulate a max-heap:\nheapq.heappush(heap, -x)\n-max(heapq.heappop(heap))",
    "crumbs": [
      "Interview-prep",
      "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html#deque-vs-heapq-know-the-difference",
    "href": "Interview-prep/python_basics.html#deque-vs-heapq-know-the-difference",
    "title": "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "🔁 deque vs heapq: Know the Difference",
    "text": "🔁 deque vs heapq: Know the Difference\n\n\n\nFeature\ndeque\nheapq\n\n\n\n\nType\nDouble-ended queue\nBinary heap (min-heap)\n\n\nInsert/Remove\nO(1) at both ends\nO(log n)\n\n\nUse Case\nQueues, stacks\nPriority queues, heaps",
    "crumbs": [
      "Interview-prep",
      "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html#time-complexity-reference-table",
    "href": "Interview-prep/python_basics.html#time-complexity-reference-table",
    "title": "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "🧮 Time Complexity Reference Table",
    "text": "🧮 Time Complexity Reference Table\nHere’s a quick cheat sheet for the time complexity of key operations in each structure:\n\n\n\n\n\n\n\n\n\n\nOperation\nlist\ndeque\nheapq (min-heap)\nset / dict\n\n\n\n\nAppend (end)\nO(1) amortized\nO(1)\nO(log n)\n—\n\n\nPop (end)\nO(1)\nO(1)\nO(log n)\n—\n\n\nPop (start)\nO(n)\nO(1) (popleft)\n—\n—\n\n\nInsert (start)\nO(n)\nO(1) (appendleft)\n—\n—\n\n\nSearch\nO(n)\nO(n)\nO(n)\nO(1)\n\n\nMembership Test\nO(n)\nO(n)\nO(n)\nO(1)\n\n\nPush to Heap\n—\n—\nO(log n)\n—\n\n\nPop from Heap\n—\n—\nO(log n)\n—\n\n\nPeek Min (heap[0])\n—\n—\nO(1)\n—\n\n\nGet by Key\n—\n—\n—\nO(1) (dict)",
    "crumbs": [
      "Interview-prep",
      "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html#final-thoughts",
    "href": "Interview-prep/python_basics.html#final-thoughts",
    "title": "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "🧠 Final Thoughts",
    "text": "🧠 Final Thoughts\nMastery isn’t about memorizing APIs—it’s about understanding patterns, recognizing trade-offs, and writing code that communicates intent. Whether you’re preparing for interviews or just refining your craft, these tools and techniques will serve you well.\n\nIf you found this useful, I’d love to hear what you’re brushing up on—or what you’d like to see next. You can also check out my other technical deep dives here.\nHappy coding. 🚀",
    "crumbs": [
      "Interview-prep",
      "🧠 A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "figma-plugin.html",
    "href": "figma-plugin.html",
    "title": "Getting Started",
    "section": "",
    "text": "https://www.figma.com/plugin-docs/plugin-quickstart-guide/\nNext, install TypeScript using the command:\nnpm install -g typescript\nif you get a permission error try the command with sudo.\nFinally, in the directory of your plugin, get the latest type definitions for the plugin API by running:\nnpm install --save-dev @figma/plugin-typings\nUsing TypeScript requires a compiler to convert TypeScript (code.ts) into JavaScript (code.js) for the browser to run.\nWe recommend writing TypeScript code using Visual Studio code:\n\nOpen project directory in Visual Studio Code.\nCompile TypeScript to JavaScript: Run the “Terminal &gt; Run Build Task…” menu item, then select “npm: watch”. You will have to do this again every time you reopen Visual Studio Code.\n\n\nHot reloading Figma provides the option to hot reload your plugin to speed up the development process. As you edit the plugin code and rebuild, the plugin will automatically restart with the latest changes. If turned off, you will need to manually restart the plugin.\nplugins &gt; Development &gt;hot reload plugins",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "ML/intro.html",
    "href": "ML/intro.html",
    "title": "ML Space",
    "section": "",
    "text": "A random collection of ML related resources that I keep collecting like trinkets frm my travels.\nLLMs have taken the world by storm. They are close to what AI has been promising for the last 50 years. The time is ripe to start learning about them. This repo is a collection of resources that I found useful.\nYou can find notes on my readings here: ML Notes",
    "crumbs": [
      "ML",
      "ML Space"
    ]
  },
  {
    "objectID": "ML/intro.html#techincal-resources",
    "href": "ML/intro.html#techincal-resources",
    "title": "ML Space",
    "section": "Techincal Resources",
    "text": "Techincal Resources\n\nAwesome LLM: always a big fan of awesome github repos. this one is quentessential for LLMs",
    "crumbs": [
      "ML",
      "ML Space"
    ]
  },
  {
    "objectID": "ML/intro.html#ai-tools",
    "href": "ML/intro.html#ai-tools",
    "title": "ML Space",
    "section": "AI Tools",
    "text": "AI Tools\n\nEssentials\n\nGithub Copilot is TOP tier coding ESSENTIAL ✨\nChat GPT duh!",
    "crumbs": [
      "ML",
      "ML Space"
    ]
  },
  {
    "objectID": "ML/llm_output_parser.html",
    "href": "ML/llm_output_parser.html",
    "title": "Intro to LangChain Output Parsers",
    "section": "",
    "text": "If you have fiddled around with ChatGPT or LangChain yet, you would have realised how difficult it is to get the outcome we expect everytime. For whatever reason, we might expect a list, or a table and it would output a lot of text that we never asked for.\nLet’s follow an example to see what is the issue we usually face with LLMs and how we can use Output Parsers to resolve it. But first, some setup!",
    "crumbs": [
      "ML",
      "Intro to LangChain Output Parsers"
    ]
  },
  {
    "objectID": "ML/llm_output_parser.html#bonus",
    "href": "ML/llm_output_parser.html#bonus",
    "title": "Intro to LangChain Output Parsers",
    "section": "Bonus",
    "text": "Bonus\n\n\n\ncan’t end this without a midjourney pikachu encounter. prompt: “pikachu in legend of zelda, cgi, high quality render”",
    "crumbs": [
      "ML",
      "Intro to LangChain Output Parsers"
    ]
  },
  {
    "objectID": "ML/ml_tweet_graveyard.html",
    "href": "ML/ml_tweet_graveyard.html",
    "title": "ML Tweet Graveyard",
    "section": "",
    "text": "Andrej Karpathy beatifully covers why llama.cpp works.\n\n\n\"How is LLaMa.cpp possible?\" great post by @finbarrtimbers https://t.co/yF43inlY87llama.cpp surprised many people (myself included) with how quickly you can run large LLMs on small computers, e.g. 7B runs @ ~16 tok/s on a MacBook. Wait don't you need supercomputers to work… pic.twitter.com/EIp9iPkZ6x\n\n— Andrej Karpathy (@karpathy) August 15, 2023",
    "crumbs": [
      "ML",
      "ML Tweet Graveyard"
    ]
  },
  {
    "objectID": "ML/instruction_tuning.html",
    "href": "ML/instruction_tuning.html",
    "title": "Instruction Tuning Notes",
    "section": "",
    "text": "💡 This post assumes familiarity with large language models and their training and finetuning. We cover the idea without deep diving into the technical details.\n\nPretraining LLMs on “next token prediction” task has proven to show incredible generalisation powers as long as you throw enough data, parameters and compute at it. However, it is possible to get more out of your language model if you finetune it on a smaller set. Many have already experimented with finetuning LLMs on downstream tasks. But you can also improve their generalisation and instruction-following abilities by using a dataset that presents tasks as instructions and expects LLM to predict the output.",
    "crumbs": [
      "ML",
      "Instruction Tuning Notes"
    ]
  },
  {
    "objectID": "ML/instruction_tuning.html#context",
    "href": "ML/instruction_tuning.html#context",
    "title": "Instruction Tuning Notes",
    "section": "",
    "text": "💡 This post assumes familiarity with large language models and their training and finetuning. We cover the idea without deep diving into the technical details.\n\nPretraining LLMs on “next token prediction” task has proven to show incredible generalisation powers as long as you throw enough data, parameters and compute at it. However, it is possible to get more out of your language model if you finetune it on a smaller set. Many have already experimented with finetuning LLMs on downstream tasks. But you can also improve their generalisation and instruction-following abilities by using a dataset that presents tasks as instructions and expects LLM to predict the output.",
    "crumbs": [
      "ML",
      "Instruction Tuning Notes"
    ]
  },
  {
    "objectID": "ML/instruction_tuning.html#what-is-instruction-tuning",
    "href": "ML/instruction_tuning.html#what-is-instruction-tuning",
    "title": "Instruction Tuning Notes",
    "section": "What is Instruction Tuning?",
    "text": "What is Instruction Tuning?\n\n“A form of fine-tuning that improves a generative AI model’s ability to follow instructions. Instruction tuning involves training a model on a series of instructions prompts, typically covering a wide variety of tasks. The resulting instruction-tuned model then tends to generate useful responses to zero-shot prompts across a variety of tasks.” - Google Dev Page",
    "crumbs": [
      "ML",
      "Instruction Tuning Notes"
    ]
  },
  {
    "objectID": "ML/instruction_tuning.html#why-instruction-tuning",
    "href": "ML/instruction_tuning.html#why-instruction-tuning",
    "title": "Instruction Tuning Notes",
    "section": "Why Instruction Tuning?",
    "text": "Why Instruction Tuning?\nGiven the scaling law, we can expect models to get better with more dataset and parameters. But it is possible to squeeze out more performance by methods like instruction tuning that allow few-shot learning (also called in-context learning; ICL) and zero-shot learning. This way, user can provide prompts with instructions and expect model to perform tasks accordingly.\nThink pretraining as barebones for building world knowledge and instruction tuning as lessons on problem solving.",
    "crumbs": [
      "ML",
      "Instruction Tuning Notes"
    ]
  },
  {
    "objectID": "ML/instruction_tuning.html#how",
    "href": "ML/instruction_tuning.html#how",
    "title": "Instruction Tuning Notes",
    "section": "How?",
    "text": "How?\nIt’s simple, just use the dataset with an input construction as described below. Different models use different approaches but the idea is same, provide instructions that have details of the task and then ask model to predict the output.\n\n\n\nOpenAI InstructGPT\n\n\n\n\n\nFlanT5\n\n\nref(FLAN-T5)\nStanford NLP group released Alpaca: an instruction-tuned model that starts from LLaMA and uses instructions generated by GPT-3 as a dataset\n\n💡 Note on Alpaca: However, the original implementation is less accessible due to licensing constraints of the underlying LLaMA model. Furthermore, users have noted potential noise in the synthetic dataset. Hence, it may be better to explore a fully accessible model that is already trained on high-quality (but less diverse) instructions such as Flan-T5. - flan-alpaca-gpt4-xl\n\n\n\n\nT0 model\n\n\nimage from T0 paper",
    "crumbs": [
      "ML",
      "Instruction Tuning Notes"
    ]
  },
  {
    "objectID": "ML/instruction_tuning.html#conclusion",
    "href": "ML/instruction_tuning.html#conclusion",
    "title": "Instruction Tuning Notes",
    "section": "Conclusion",
    "text": "Conclusion\nIt’s nice but the amount of data needed is still pretty large (~10k-100k). Also, deciding the best format for instructions and output is another unbounded experiment.\n\nReferences\nOuterbounds Blog - Beautifully covers Instruction Tuning\nFlan-T5 - introduces “instruction tuning”\nMulti-task finetuning paper\nOpenAI paper Instruct GPT - RLHF with Supervised finetuning step that is instruction tuning\nAlpaca - Open source instruction tuned model\nscaling law",
    "crumbs": [
      "ML",
      "Instruction Tuning Notes"
    ]
  },
  {
    "objectID": "website_tutorial.html",
    "href": "website_tutorial.html",
    "title": "How to: make your own blog?",
    "section": "",
    "text": "genesis\n\n\nNow let’s get to the very reason you are here! ### You will love it if You spent countless hours on jupyter notebooks and markdown. I love it for the simplicity. Love how I can break down things into little cells of their own and keep going compartmentalizing my blog. Into folders, into cells and into my mind. All along with the incredible power of python. And the great thing about it is that you can hos tit on github pages too! free free free!\n\nNBDEV\nHere’s the post that led me to it. Huge shoutout to Jonathan Soma’s blog (please check it out it is amaaazing). This blog eventually led me to nbdev and here I am.\n\n\nHow to use it?\nHonestly, you just need to follow their tutorial and you are good to go. It covers everything about setting up a repository to writing your notebooks. It is wordy and if you want to me write a cut-to-the-chase version then let me know in the comments!\nDon’t forget to leverage the powerful formatting with quatro that is that is the backbone of this setup. Nbdev is using quatro to convert these cheeky notebooks into pretty blogposts. So create a _quatro.yml file in your nbs folder. Head over to quatro docs for the REAL documentation that helps you customize easily.\nI enabled sidebar, comments, theme and other customizations thanks to quatro docs. Needless to say, I LOVE playing around with these customizations and I hope you do too!\n\n\nRedirecting to your page\nGo to settings of your repository, Pages section of the left panel and enter your domain name in the custom domain box. Give it a few minutes to verify and them see your changes reflected!\nHowever, whenever I made a commit to my github repo, github build would reset my CNAME and I would have to go back and update it again. To my help came this nice github discussion. Simply create a CNAME file with the subdomain you want to redirect to. For example I use blog.ashantanu.com. I had to add this CNAME record on my domain registry (GoDaddy, NameCheap, Wix or whereever you purchased your domain name from).\n\n\nAlternatives\n\nGithub Pages with Jekyll I have gone over almost every jekyll theme in hopes of getting it right and bending it to my will. I tried the barber theme (great aesthetics) and teXt theme. Both incredible, spent infinite time working on them but maintaining them was SO tough. Constantly trying to keep up with the versions, setting up environment, failing to do so and then reinventing the week. A vicious tirade. So I decided against it.\nWix and other website builders Great for making websites, but terribly slow for blogs. Wanted something neat that can hold experiments and markdown. So I dropped it. BUT! made my website with it and love every bit of it. Check it out here.\nMedium I love medium. I love the aesthetics, the simplicity, the community. But the paywall, hate the paywall. I wanted something that I can call my own. So I decided against it again. But I do have some older posts on medium. Check it out here.\nFast.ai They have a pretty neat template that can set you up in minutes.It’s barebones but you can customize and go a long way. It helps you write quickly and get your content out there. I used it for a while but wanted something more customizable. Check it out here.\n\n\n\nConclusion\nThe most difficult part of writing your own blog is taking the first step. I know I sound like every other self-help Guru but belive me it is true. I know I will make mistakes on the way and that is FINE. So just pick the method you find easiest and suitable to your needs and get started! And don’t forget to tell me about it because I’d love to hear your stories!\nGotta end with midj image\n\n\n\nbelieve it or not, prompt is “pikachu as a jedi”",
    "crumbs": [
      "How to: make your own blog?"
    ]
  }
]