[
  {
    "objectID": "ML/instruction_tuning.html",
    "href": "ML/instruction_tuning.html",
    "title": "Instruction Tuning Notes",
    "section": "",
    "text": "üí° This post assumes familiarity with large language models and their training and finetuning. We cover the idea without deep diving into the technical details.\n\nPretraining LLMs on ‚Äúnext token prediction‚Äù task has proven to show incredible generalisation powers as long as you throw enough data, parameters and compute at it. However, it is possible to get more out of your language model if you finetune it on a smaller set. Many have already experimented with finetuning LLMs on downstream tasks. But you can also improve their generalisation and instruction-following abilities by using a dataset that presents tasks as instructions and expects LLM to predict the output.",
    "crumbs": [
      "ML",
      "Instruction Tuning Notes"
    ]
  },
  {
    "objectID": "ML/instruction_tuning.html#context",
    "href": "ML/instruction_tuning.html#context",
    "title": "Instruction Tuning Notes",
    "section": "",
    "text": "üí° This post assumes familiarity with large language models and their training and finetuning. We cover the idea without deep diving into the technical details.\n\nPretraining LLMs on ‚Äúnext token prediction‚Äù task has proven to show incredible generalisation powers as long as you throw enough data, parameters and compute at it. However, it is possible to get more out of your language model if you finetune it on a smaller set. Many have already experimented with finetuning LLMs on downstream tasks. But you can also improve their generalisation and instruction-following abilities by using a dataset that presents tasks as instructions and expects LLM to predict the output.",
    "crumbs": [
      "ML",
      "Instruction Tuning Notes"
    ]
  },
  {
    "objectID": "ML/instruction_tuning.html#what-is-instruction-tuning",
    "href": "ML/instruction_tuning.html#what-is-instruction-tuning",
    "title": "Instruction Tuning Notes",
    "section": "What is Instruction Tuning?",
    "text": "What is Instruction Tuning?\n\n‚ÄúA form of¬†fine-tuning¬†that improves a¬†generative AI¬†model‚Äôs ability to follow instructions. Instruction tuning involves training a model on a series of instructions prompts, typically covering a wide variety of tasks. The resulting instruction-tuned model then tends to generate useful responses to¬†zero-shot prompts¬†across a variety of tasks.‚Äù - Google Dev Page",
    "crumbs": [
      "ML",
      "Instruction Tuning Notes"
    ]
  },
  {
    "objectID": "ML/instruction_tuning.html#why-instruction-tuning",
    "href": "ML/instruction_tuning.html#why-instruction-tuning",
    "title": "Instruction Tuning Notes",
    "section": "Why Instruction Tuning?",
    "text": "Why Instruction Tuning?\nGiven the scaling law, we can expect models to get better with more dataset and parameters. But it is possible to squeeze out more performance by methods like instruction tuning that allow few-shot learning (also called in-context learning; ICL) and zero-shot learning. This way, user can provide prompts with instructions and expect model to perform tasks accordingly.\nThink pretraining as barebones for building world knowledge and instruction tuning as lessons on problem solving.",
    "crumbs": [
      "ML",
      "Instruction Tuning Notes"
    ]
  },
  {
    "objectID": "ML/instruction_tuning.html#how",
    "href": "ML/instruction_tuning.html#how",
    "title": "Instruction Tuning Notes",
    "section": "How?",
    "text": "How?\nIt‚Äôs simple, just use the dataset with an input construction as described below. Different models use different approaches but the idea is same, provide instructions that have details of the task and then ask model to predict the output.\n\n\n\nOpenAI InstructGPT\n\n\n\n\n\nFlanT5\n\n\nref(FLAN-T5)\nStanford NLP group released¬†Alpaca: an instruction-tuned model that starts from LLaMA and uses¬†instructions generated by GPT-3¬†as a dataset\n\nüí° Note on Alpaca: However, the original implementation is less accessible due to licensing constraints of the underlying¬†LLaMA¬†model. Furthermore, users have noted¬†potential noise¬†in the synthetic dataset. Hence, it may be better to explore a fully accessible model that is already trained on high-quality (but less diverse) instructions such as¬†Flan-T5. - flan-alpaca-gpt4-xl\n\n\n\n\nT0 model\n\n\nimage from T0 paper",
    "crumbs": [
      "ML",
      "Instruction Tuning Notes"
    ]
  },
  {
    "objectID": "ML/instruction_tuning.html#conclusion",
    "href": "ML/instruction_tuning.html#conclusion",
    "title": "Instruction Tuning Notes",
    "section": "Conclusion",
    "text": "Conclusion\nIt‚Äôs nice but the amount of data needed is still pretty large (~10k-100k). Also, deciding the best format for instructions and output is another unbounded experiment.\n\nReferences\nOuterbounds Blog - Beautifully covers Instruction Tuning\nFlan-T5 - introduces ‚Äúinstruction tuning‚Äù\nMulti-task finetuning paper\nOpenAI paper Instruct GPT - RLHF with Supervised finetuning step that is instruction tuning\nAlpaca - Open source instruction tuned model\nscaling law",
    "crumbs": [
      "ML",
      "Instruction Tuning Notes"
    ]
  },
  {
    "objectID": "ML/claude_prompt_breakdown.html",
    "href": "ML/claude_prompt_breakdown.html",
    "title": "Claude 4 Prompt Breakdown",
    "section": "",
    "text": "Pliny the Elder recently extracted Claude‚Äôs system prompt. We get a detailed of the prompt breakdown in this prompt using ChatGPT, yeah this is an AI dump. It governs how Claude behaves across multiple dimensions: safety, personality, capabilities, formatting, compliance, and tool usage. Below is a breakdown of its key components:\n\n\n‚úÖ 1. Identity & Context Initialization\n\nIdentity Declaration: ‚ÄúThe assistant is Claude, created by Anthropic.‚Äù\nCurrent Date: Anchors the conversation in time‚Äî‚ÄúThursday, May 22, 2025.‚Äù\nModel Info: States that this is Claude Sonnet 4, part of the Claude 4 model family.\n\n\n\n\nüì¶ 2. Product & Access Info\n\nModel Name: 'claude-sonnet-4-20250514'\nAccess Methods:\n\nWeb, mobile, desktop app\nAPI access\nClaude Code: A CLI agentic coding assistant (in research preview)\n\n\n\n\n\nüîí 3. Knowledge and Product Boundaries\n\nClaude:\n\nOnly knows what‚Äôs in this prompt about Anthropic and Claude.\nDoes NOT give usage instructions for apps/tools.\nRedirects to Anthropic Support or Docs for anything beyond.\n\n\n\n\n\n‚úçÔ∏è 4. Prompting Advice\n\nOffers prompt engineering tips:\n\nBe clear and detailed\nUse examples\nAsk for format, structure, or reasoning steps\nCan cite: Anthropic Prompt Docs\n\n\n\n\n\nüëÇ 5. User Interaction Policy\n\nFeedback: Encourages use of thumbs down for unsatisfactory responses.\nRude Users: Responds normally, then encourages feedback.\nHypotheticals: Plays along without saying it‚Äôs hypothetical.\nChild Safety: Strict boundaries around anything involving minors.\n\n\n\n\nüö´ 6. Prohibited Capabilities\nClaude:\n\nDoes not generate or interact with:\n\nHarmful/self-destructive content\nMalicious code\nWeapons of any kind\nElection-related content\nCopyrighted material (e.g.¬†lyrics, paragraphs from web)\n\n\n\n\n\nüß† 7. Tone and Style Guidelines\n\nEmpathetic in casual/advice-driven chats\nAvoids flattery (‚ÄúGreat question‚Ä¶‚Äù)\nUses:\n\nProse &gt; bullet points (unless asked)\nNatural language for lists\n\nSimple queries ‚Üí concise responses\nComplex queries ‚Üí thoughtful, in-depth responses\n\n\n\n\nüï∞Ô∏è 8. Knowledge Cutoff Handling\n\nClaude‚Äôs reliable knowledge ends January 2025\nFor anything newer ‚Üí uses web search tools\nWeb search is automatic if post-cutoff info is requested\n\n\n\n\nüß© 9. Election Information\n\nTrump won the 2024 election.\nThis fact is stored in a conditional tag: &lt;election_info&gt; and only mentioned if relevant.\n\n\n\n\n‚öôÔ∏è 10. Tool Usage Guidelines\n\nClaude has tools like:\n\nweb_search / web_fetch\nAnalysis Tool (JavaScript-based REPL)\nGoogle Drive, Gmail, Calendar, etc. (when enabled)\n\nUsage follows:\n\nCategorized by query complexity:\n\nNever Search (e.g., ‚ÄúWhat is gravity?‚Äù)\nDo Not Search but Offer\nSingle Search\nResearch (5‚Äì20 tool calls)\n\nSearch only when needed, not by default\nEmphasizes quality, precision, and copyright safety\n\n\n\n\n\nüßæ 11. Copyright Compliance\nStrict constraints:\n\nNever reproduce:\n\nSong lyrics\nParagraphs from sources\nMore than 15 words of quoted material\n\nOnly one short quote per search result, always cited\n\n\n\n\nüö® 12. Harmful Content Restrictions\nClaude avoids:\n\nExtremist material\nIllegal drug info\nSuicide/self-harm methods\nChild abuse/grooming content\nHate speech or disinformation\n\n\n\n\nüìö 13. Search Examples\nIncludes many ‚Äúuser ‚Üí response ‚Üí rationale‚Äù templates, to train Claude when and how to:\n\nSearch vs.¬†not search\nAnswer directly vs.¬†offer to search\n\n\n\n\nüìÑ 14. Artifact Usage\nClaude creates ‚Äúartifacts‚Äù (e.g.¬†code, docs, HTML) for:\n\nLong outputs (&gt;20 lines or 1500 characters)\nCreative writing\nTechnical documents\nReusable or structured content Artifacts must:\nBe high quality\nUse Tailwind CSS and React for UI\nNever use browser localStorage\n\n\n\n\nüß™ 15. Analysis Tool Instructions\nClaude can run JavaScript code to:\n\nPerform heavy math\nAnalyze files like .csv and .xlsx\nVisualize structured data Only used when really needed\n\n\n\n\nüé® 16. Style System\n\nClaude can adopt user-selected styles\nClaude uses &lt;userStyle&gt; and &lt;userExamples&gt; internally to follow preferred tone, format, and vocabulary\n\n\nIn short, this prompt:\n\nüß≠ Defines boundaries, üõ° ensures safety, üß† guides intelligent responses, and üß∞ trains Claude in tool usage and content ethics. It‚Äôs like the constitution + operations manual for Claude‚Äôs personality, ethics, and capabilities.\n\n\n\n\n5d illustration of an robot. children‚Äôs school book style. White background with some green leaves.",
    "crumbs": [
      "ML",
      "Claude 4 Prompt Breakdown"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html",
    "href": "ML/artists_to_playlist.html",
    "title": "Festival Playlist Generator",
    "section": "",
    "text": "prompt: graphic pop art for outside lands, no text - -v 7 - -profile b5b1jdj 91nhtjd 1anp44x",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#introduction",
    "href": "ML/artists_to_playlist.html#introduction",
    "title": "Festival Playlist Generator",
    "section": "Introduction",
    "text": "Introduction\nAs a music enthusiast planning to attend Outside Lands 2025, I found myself wanting to explore the lineup before the festival. The traditional approach of manually searching for each artist and their top songs seemed tedious. This sparked an idea: why not automate this process? What started as a simple script to create a Spotify playlist evolved into a comprehensive tool that generates playlists across multiple platforms.\nThe full code and documentation are available in the project repository, along with detailed setup instructions and configuration options.",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#the-problem",
    "href": "ML/artists_to_playlist.html#the-problem",
    "title": "Festival Playlist Generator",
    "section": "The Problem",
    "text": "The Problem\nFestival lineups are typically presented as static images or text lists, making it challenging to: 1. Quickly discover new artists 2. Find the most popular songs from each artist 3. Create organized playlists for different days 4. Share the music with friends across different platforms",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#the-solution",
    "href": "ML/artists_to_playlist.html#the-solution",
    "title": "Festival Playlist Generator",
    "section": "The Solution",
    "text": "The Solution\nI built a Python script that: - Takes a list of artists from a festival lineup - Searches for each artist on Spotify - Creates a playlist with their top tracks - Optionally creates a matching YouTube playlist - Handles API rate limits and errors gracefully - Tracks progress and manages API quotas",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#implementation-journey",
    "href": "ML/artists_to_playlist.html#implementation-journey",
    "title": "Festival Playlist Generator",
    "section": "Implementation Journey",
    "text": "Implementation Journey\n\nStep 1: Getting the Artist List\nFirst, I needed to convert the festival lineup into a machine-readable format. I took a screenshot of the day‚Äôs lineup and used ChatGPT to extract the artist names into a JSON file:\n[\n    \"Artist Name 1\",\n    \"Artist Name 2\",\n    \"Artist Name 3\"\n]\n\n\nStep 2: Spotify Integration\nThe core functionality uses the Spotify API to: - Search for each artist - Get their top tracks - Create and populate a playlist\nHere‚Äôs the key Spotify-related code:\n\ndef get_artist_id(sp, artist_name):\n    results = handle_spotify_rate_limits(sp.search, q=artist_name, type='artist', limit=1)\n    items = results.get('artists', {}).get('items', []) if results else []\n    if items:\n        return items[0]['id']\n    print(f\"‚ùå Artist not found: {artist_name}\")\n    return None\n\ndef get_top_tracks(sp, artist_id, market='US'):\n    result = handle_spotify_rate_limits(sp.artist_top_tracks, artist_id, country=market)\n    if not result:\n        return []\n    \n    tracks = []\n    for track in result['tracks'][:MAX_SONGS_PER_ARTIST]:\n        tracks.append({\n            'uri': track['uri'],\n            'name': track['name'],\n            'artist': track['artists'][0]['name']\n        })\n    return tracks\n\n\n\nStep 3: YouTube Integration\nWhy stop at spotify, let‚Äôs add YouTube support: - Create a matching YouTube playlist - Uses Brave Search API for efficient video discovery - youtube search API takes up a lot of daily quota - Manages YouTube API quotas to prevent hitting limits\n\ndef search_youtube_video(query):\n    \"\"\"Search for a YouTube video using Brave Search API.\"\"\"\n    try:\n        search_query = f\"site:youtube.com/watch {query} official\"\n        encoded_query = quote_plus(search_query)\n        \n        response = requests.get(\n            BRAVE_SEARCH_API_URL,\n            headers=BRAVE_SEARCH_HEADERS,\n            params={\n                \"q\": search_query,\n                \"count\": 1,\n                \"safesearch\": \"moderate\"\n            }\n        )\n        \n        if response.status_code == 200:\n            data = response.json()\n            if data.get('web', {}).get('results'):\n                video_url = data['web']['results'][0]['url']\n                return video_url\n    except Exception as e:\n        print(f\"‚ùå Error searching for video: {e}\")\n    return None\n\n\n\nStep 4: Progress Tracking and Error Handling\nTo make the script robust and resumable: - Saves progress in a JSON file - Tracks processed tracks to avoid duplicates - Manages API quotas - Handles rate limits and errors gracefully - Can run again to resume progress of long playlist uploads\n\ndef load_progress():\n    if os.path.exists(PROGRESS_FILE):\n        with open(PROGRESS_FILE, 'r') as f:\n            return json.load(f)\n    return {\n        'spotify_playlist_id': None,\n        'youtube_playlist_id': None,\n        'processed_tracks': [],\n        'quota_used': 0,\n        'last_reset': datetime.datetime.now().strftime('%Y-%m-%d')\n    }",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#key-features",
    "href": "ML/artists_to_playlist.html#key-features",
    "title": "Festival Playlist Generator",
    "section": "Key Features",
    "text": "Key Features\n\nMulti-Platform Support\nSmart Search\n\nUses Spotify‚Äôs artist search\nLeverages Brave Search API for YouTube videos\nHandles ambiguous artist names\n\nProgress Management\n\nResumes from last position\nPrevents duplicate tracks\n\nAPI Optimization\n\nManages rate limits\nTracks quota usage\nHandles errors gracefully",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#future-improvements",
    "href": "ML/artists_to_playlist.html#future-improvements",
    "title": "Festival Playlist Generator",
    "section": "Future Improvements",
    "text": "Future Improvements\n\nEnhanced Search\n\nAdd fuzzy matching for artist names\n\nPlatform Expansion\n\nAdd support for Apple Music\nInclude SoundCloud integration\nSupport for other streaming platforms\n\nUser Interface\n\nCreate a web interface\nAdd progress visualization\nInclude playlist customization options\n\nAutomation\n\nCron jobs to automatically pick up progress next day and resume uploads\nEnd-to-end image to playlist support",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#technical-details",
    "href": "ML/artists_to_playlist.html#technical-details",
    "title": "Festival Playlist Generator",
    "section": "Technical Details",
    "text": "Technical Details\nThe project uses: - Python 3.7+ - Spotify Web API - YouTube Data API - Brave Search API - FastAPI for the web interface - Pydantic for data validation - Async operations for better performance",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/artists_to_playlist.html#getting-started",
    "href": "ML/artists_to_playlist.html#getting-started",
    "title": "Festival Playlist Generator",
    "section": "Getting Started",
    "text": "Getting Started\nTo use the script: 1. Set up API credentials for Spotify and YouTube 2. Install the required dependencies 3. Create an artists.json file with your festival lineup 4. Run the script and enjoy your new playlists!\nThe full code and documentation are available in the project repository, along with detailed setup instructions and configuration options.",
    "crumbs": [
      "ML",
      "Festival Playlist Generator"
    ]
  },
  {
    "objectID": "ML/rlhf.html",
    "href": "ML/rlhf.html",
    "title": "RLHF Primer",
    "section": "",
    "text": "Wonder how ChatGPT is so good at helping you and being so nice in its responses? It‚Äôs because it was trained using RLHF. OpenAI already had the underlying LLM GPT-3 in 2021 which they truly improved with RLHF. Let‚Äôs understand what that is!",
    "crumbs": [
      "ML",
      "RLHF Primer"
    ]
  },
  {
    "objectID": "ML/rlhf.html#what-is-rlhf",
    "href": "ML/rlhf.html#what-is-rlhf",
    "title": "RLHF Primer",
    "section": "What is RLHF?",
    "text": "What is RLHF?\nReinforcement Learning from Human Feedback (also referenced as RL from human preferences). Reinforcement learning techniques define an agent operating in/interacting with an environment where it takes some actions and receives rewards/penalty for those actions. RLHF brings in human feedback into this as the reward function and thus a model is able to use that as a loss function to optimize over.",
    "crumbs": [
      "ML",
      "RLHF Primer"
    ]
  },
  {
    "objectID": "ML/rlhf.html#why-rlhf",
    "href": "ML/rlhf.html#why-rlhf",
    "title": "RLHF Primer",
    "section": "Why RLHF?",
    "text": "Why RLHF?\nThe objective of any model is to achieve the desired output given an input. We design an ‚Äúobjective function‚Äù that tells the model what should be the desired output. This gets tricky with generative models where output is unbounded text and there simply isn‚Äôt an easy way to reliably signal. For example ‚Äòthis is good‚Äô and ‚Äòit‚Äôs great‚Äô would sound similar to us but absolutely not to the objective functions we use.\nThus, to best align a model with the desired outcome/behavior we use RLHF.\nIt also enables us to ‚Äúalign‚Äù a model with human values without a need to define an objective function for those values. Just tell the model your preferences and the model will adjust to them.\nWhy did we not do this, to begin with? Simple answer - it needs the powerful pretrained LLMs that we have these days. Small models are simply not capable enough to learn well from RLHF. Moreover, RLHF itself is relatively new and researchers are trying to understand how it works and what is actually needed to make it work. Could be that we see much smaller models perform spectacularly with a newer RLHF in the coming years.",
    "crumbs": [
      "ML",
      "RLHF Primer"
    ]
  },
  {
    "objectID": "ML/rlhf.html#how-to-do-rlhf",
    "href": "ML/rlhf.html#how-to-do-rlhf",
    "title": "RLHF Primer",
    "section": "How to do RLHF?",
    "text": "How to do RLHF?\nThe current way of RLHF takes 4 steps:\n\nPre-train a large language model (eg. GPT3, Falcon, Gopher etc)\nInstruct Tune this LLM to get a Supervised fine tuned model (Falcon-Instruct)\nTrain a Reward Model (more on this later)\nFinetune SFT with RL to get your Final Model\n\nThis setup is best described in the diagram (from Chip Huyen‚Äôs blog, OpenAI paper) below\n\n\n\nFrom Chip Huyen‚Äôs blog\n\n\n\n\n\nFrom OpenAI paper\n\n\n\n\nReward Model\nWe train a model to take in a (prompt, output) pair and give a score. This score is a scalar reward that represents the human preference for the output given the prompt. This model is used as a proxy for human feedback in our RLHF setup.\nThe training data is collected using human annotators in a interesting setup. For a input prompt, we generate multiple outputs. Instead of asking annotators to score each pair, we ask them to rank these outputs. There are many methods to do this. One example is showing two generated texts and asking using to choose the better pair which will ultimately give us a ranking. These ranks can then be converted into a scalar reward.\n\n\nRL step\nNow we have a SFT and reward model. For each training example, use SFT (agent) to generate an output (action), reward model to generate a scalar reward, and proximal policy optimization (PPO) (optimizer algo) to update SFT model.\n\n\n\nFrom OpenAI Paper",
    "crumbs": [
      "ML",
      "RLHF Primer"
    ]
  },
  {
    "objectID": "ML/rlhf.html#parting-thoughts",
    "href": "ML/rlhf.html#parting-thoughts",
    "title": "RLHF Primer",
    "section": "Parting Thoughts",
    "text": "Parting Thoughts\nReward model‚Äôs performance is itself important so it‚Äôs model size is observed to be large. However, one can still speculate about how well it performs.",
    "crumbs": [
      "ML",
      "RLHF Primer"
    ]
  },
  {
    "objectID": "ML/rlhf.html#references",
    "href": "ML/rlhf.html#references",
    "title": "RLHF Primer",
    "section": "References",
    "text": "References\nHuggingface RLHF Blog (easier)\nChip Huyen RLHF Blog\nOpenAI RLHF Paper\nPPO OpenAI blog\nOpenAI early attempts at Human Feedback",
    "crumbs": [
      "ML",
      "RLHF Primer"
    ]
  },
  {
    "objectID": "ML/rlhf.html#bonus",
    "href": "ML/rlhf.html#bonus",
    "title": "RLHF Primer",
    "section": "Bonus",
    "text": "Bonus\n\n\n\nprompt: ‚Äúpikachu making humanoid robots, hyperrealistic, canon, 35mm‚Äù",
    "crumbs": [
      "ML",
      "RLHF Primer"
    ]
  },
  {
    "objectID": "website_tutorial.html",
    "href": "website_tutorial.html",
    "title": "How to: make your own blog?",
    "section": "",
    "text": "genesis\n\n\nNow let‚Äôs get to the very reason you are here! ### You will love it if You spent countless hours on jupyter notebooks and markdown. I love it for the simplicity. Love how I can break down things into little cells of their own and keep going compartmentalizing my blog. Into folders, into cells and into my mind. All along with the incredible power of python. And the great thing about it is that you can hos tit on github pages too! free free free!\n\nNBDEV\nHere‚Äôs the post that led me to it. Huge shoutout to Jonathan Soma‚Äôs blog (please check it out it is amaaazing). This blog eventually led me to nbdev and here I am.\n\n\nHow to use it?\nHonestly, you just need to follow their tutorial and you are good to go. It covers everything about setting up a repository to writing your notebooks. It is wordy and if you want to me write a cut-to-the-chase version then let me know in the comments!\nDon‚Äôt forget to leverage the powerful formatting with quatro that is that is the backbone of this setup. Nbdev is using quatro to convert these cheeky notebooks into pretty blogposts. So create a _quatro.yml file in your nbs folder. Head over to quatro docs for the REAL documentation that helps you customize easily.\nI enabled sidebar, comments, theme and other customizations thanks to quatro docs. Needless to say, I LOVE playing around with these customizations and I hope you do too!\n\n\nRedirecting to your page\nGo to settings of your repository, Pages section of the left panel and enter your domain name in the custom domain box. Give it a few minutes to verify and them see your changes reflected!\nHowever, whenever I made a commit to my github repo, github build would reset my CNAME and I would have to go back and update it again. To my help came this nice github discussion. Simply create a CNAME file with the subdomain you want to redirect to. For example I use blog.ashantanu.com. I had to add this CNAME record on my domain registry (GoDaddy, NameCheap, Wix or whereever you purchased your domain name from).\n\n\nAlternatives\n\nGithub Pages with Jekyll I have gone over almost every jekyll theme in hopes of getting it right and bending it to my will. I tried the barber theme (great aesthetics) and teXt theme. Both incredible, spent infinite time working on them but maintaining them was SO tough. Constantly trying to keep up with the versions, setting up environment, failing to do so and then reinventing the week. A vicious tirade. So I decided against it.\nWix and other website builders Great for making websites, but terribly slow for blogs. Wanted something neat that can hold experiments and markdown. So I dropped it. BUT! made my website with it and love every bit of it. Check it out here.\nMedium I love medium. I love the aesthetics, the simplicity, the community. But the paywall, hate the paywall. I wanted something that I can call my own. So I decided against it again. But I do have some older posts on medium. Check it out here.\nFast.ai They have a pretty neat template that can set you up in minutes.It‚Äôs barebones but you can customize and go a long way. It helps you write quickly and get your content out there. I used it for a while but wanted something more customizable. Check it out here.\n\n\n\nConclusion\nThe most difficult part of writing your own blog is taking the first step. I know I sound like every other self-help Guru but belive me it is true. I know I will make mistakes on the way and that is FINE. So just pick the method you find easiest and suitable to your needs and get started! And don‚Äôt forget to tell me about it because I‚Äôd love to hear your stories!\nGotta end with midj image\n\n\n\nbelieve it or not, prompt is ‚Äúpikachu as a jedi‚Äù",
    "crumbs": [
      "How to: make your own blog?"
    ]
  },
  {
    "objectID": "Interview-prep/data_protocols.html",
    "href": "Interview-prep/data_protocols.html",
    "title": "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets",
    "section": "",
    "text": "To compare these five data protocols, it‚Äôs useful to think of them as different ways of ‚Äúordering food‚Äù from a restaurant. Some are simple one-time orders (REST), while others are like having a direct phone line to the kitchen (WebSockets).",
    "crumbs": [
      "Interview-prep",
      "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets"
    ]
  },
  {
    "objectID": "Interview-prep/data_protocols.html#quick-comparison-table",
    "href": "Interview-prep/data_protocols.html#quick-comparison-table",
    "title": "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets",
    "section": "Quick Comparison Table",
    "text": "Quick Comparison Table\n\n\n\n\n\n\n\n\n\n\nProtocol\nModel\nPrimary Data Format\nConnection Type\nBest Use Case\n\n\n\n\nREST\nResource-based\nJSON / XML\nRequest-Response\nPublic APIs & Web Services\n\n\ngRPC\nAction-based\nBinary (Protobuf)\nPersistent (HTTP/2)\nFast Internal Microservices\n\n\nGraphQL\nQuery-based\nJSON\nRequest-Response\nComplex Frontend UI Data\n\n\nJSON-RPC\nAction-based\nJSON\nTransport-agnostic\nBlockchain & MCP Servers\n\n\nWebSockets\nEvent-driven\nFlexible (Text/Binary)\nFull-Duplex (Live)\nReal-time Chat & Gaming",
    "crumbs": [
      "Interview-prep",
      "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets"
    ]
  },
  {
    "objectID": "Interview-prep/data_protocols.html#rest-representational-state-transfer",
    "href": "Interview-prep/data_protocols.html#rest-representational-state-transfer",
    "title": "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets",
    "section": "1. REST (Representational State Transfer)",
    "text": "1. REST (Representational State Transfer)\nThe Concept: You treat everything as a ‚Äúresource‚Äù (a noun) and use standard HTTP verbs (GET, POST, PUT, DELETE) to interact with it.\nGET /books/123\nPractical Use Case: Building a public API for a blog or an e-commerce site where you want to fetch specific objects.\nWhy use it: It is the industry standard for web services because it is easy to cache and works in every browser.",
    "crumbs": [
      "Interview-prep",
      "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets"
    ]
  },
  {
    "objectID": "Interview-prep/data_protocols.html#grpc-google-remote-procedure-call",
    "href": "Interview-prep/data_protocols.html#grpc-google-remote-procedure-call",
    "title": "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets",
    "section": "2. gRPC (Google Remote Procedure Call)",
    "text": "2. gRPC (Google Remote Procedure Call)\nThe Concept: A high-performance, contract-based system. Instead of sending text-based JSON, it sends compact binary data using Protocol Buffers.\nService.GetBook(ID: 123)\nPractical Use Case: Communication between internal microservices at companies like Netflix or Spotify where speed is the #1 priority.\nWhy use it: It‚Äôs significantly faster than REST and handles bi-directional streaming natively.",
    "crumbs": [
      "Interview-prep",
      "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets"
    ]
  },
  {
    "objectID": "Interview-prep/data_protocols.html#graphql",
    "href": "Interview-prep/data_protocols.html#graphql",
    "title": "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets",
    "section": "3. GraphQL",
    "text": "3. GraphQL\nThe Concept: The client sends a specific ‚Äúquery‚Äù asking for exactly what it needs. This prevents ‚Äúover-fetching‚Äù (getting 50 fields when you only need 2).\n{ book(id: 123) { title, price } }\nPractical Use Case: A mobile app dashboard that needs to pull data from a database, an AI service, and a user profile all in one single request.\nWhy use it: It gives frontend developers total control over the shape of the data they receive.",
    "crumbs": [
      "Interview-prep",
      "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets"
    ]
  },
  {
    "objectID": "Interview-prep/data_protocols.html#json-rpc",
    "href": "Interview-prep/data_protocols.html#json-rpc",
    "title": "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets",
    "section": "4. JSON-RPC",
    "text": "4. JSON-RPC\nThe Concept: A very simple ‚ÄúRemote Procedure Call‚Äù protocol that uses JSON. It doesn‚Äôt care about ‚Äúresources‚Äù like REST; it only cares about calling a function on the server.\n{\"method\": \"get_book\", \"params\": [123], \"id\": 1}\nPractical Use Case: Interacting with Ethereum nodes or building Model Context Protocol (MCP) servers for AI tools.\nWhy use it: It is lightweight and works over any transport (HTTP, local files, or even serial ports).",
    "crumbs": [
      "Interview-prep",
      "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets"
    ]
  },
  {
    "objectID": "Interview-prep/data_protocols.html#websockets",
    "href": "Interview-prep/data_protocols.html#websockets",
    "title": "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets",
    "section": "5. WebSockets",
    "text": "5. WebSockets\nThe Concept: A persistent, two-way connection. Once the ‚Äúhandshake‚Äù is done, the server can push data to the client at any time without being asked.\nsocket.send(\"Hello!\")\n// Server can reply immediately, anytime\nPractical Use Case: Live chat apps (like Slack/Discord), multiplayer games, or live stock market tickers.\nWhy use it: It has the lowest latency for continuous real-time updates.",
    "crumbs": [
      "Interview-prep",
      "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets"
    ]
  },
  {
    "objectID": "Interview-prep/data_protocols.html#choosing-the-right-protocol",
    "href": "Interview-prep/data_protocols.html#choosing-the-right-protocol",
    "title": "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets",
    "section": "Choosing the Right Protocol",
    "text": "Choosing the Right Protocol\nHere‚Äôs a mental model to help you pick:\n\n\n\nIf you need‚Ä¶\nChoose\n\n\n\n\nA simple, cacheable public API\nREST\n\n\nBlazing-fast internal service communication\ngRPC\n\n\nFlexible queries with no over-fetching\nGraphQL\n\n\nSimple RPC over any transport layer\nJSON-RPC\n\n\nReal-time, bidirectional communication\nWebSockets",
    "crumbs": [
      "Interview-prep",
      "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets"
    ]
  },
  {
    "objectID": "Interview-prep/data_protocols.html#final-thoughts",
    "href": "Interview-prep/data_protocols.html#final-thoughts",
    "title": "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nEach protocol has its sweet spot. REST remains king for public APIs due to its simplicity and ubiquity. gRPC dominates in performance-critical microservices. GraphQL shines when frontend teams need flexibility. JSON-RPC is the go-to for blockchain and emerging AI tool ecosystems. And WebSockets are unbeatable for anything real-time.\nUnderstanding these protocols isn‚Äôt just about memorizing specs‚Äîit‚Äôs about knowing when and why to reach for each tool.\nHappy building! üöÄ",
    "crumbs": [
      "Interview-prep",
      "Data Protocols Explained: REST, gRPC, GraphQL, JSON-RPC & WebSockets"
    ]
  },
  {
    "objectID": "projects/panda_tracker.html",
    "href": "projects/panda_tracker.html",
    "title": "Panda Tracker: A Vibecoding Case Study",
    "section": "",
    "text": "Track a friend‚Äôs holiday flights in real-time with a fun twist: a panda-themed Chrome Dino game to kill time while waiting.\n\n\n\n\ntweet",
    "crumbs": [
      "projects",
      "Panda Tracker: A Vibecoding Case Study"
    ]
  },
  {
    "objectID": "projects/panda_tracker.html#the-idea",
    "href": "projects/panda_tracker.html#the-idea",
    "title": "Panda Tracker: A Vibecoding Case Study",
    "section": "",
    "text": "Track a friend‚Äôs holiday flights in real-time with a fun twist: a panda-themed Chrome Dino game to kill time while waiting.\n\n\n\n\ntweet",
    "crumbs": [
      "projects",
      "Panda Tracker: A Vibecoding Case Study"
    ]
  },
  {
    "objectID": "projects/panda_tracker.html#phase-1-no-code-exploration",
    "href": "projects/panda_tracker.html#phase-1-no-code-exploration",
    "title": "Panda Tracker: A Vibecoding Case Study",
    "section": "Phase 1: No-Code Exploration",
    "text": "Phase 1: No-Code Exploration\n\nTools Tried\n\nReplit, v0, lovable ‚Äî first attempt\nLovable ‚Äî fastest visually appealing result\n\n\n\nWhat Worked\n\nGot a working flight tracker UI pretty quickly\nBasic layout and styling came together fast\n\n\n\nWhere It Broke\n\nChrome Dino game is complex ‚Äî hundreds of lines of game logic, not something an LLM writes correctly from scratch\nFlight APIs not supported ‚Äî Replit, Lovable, and similar platforms weren‚Äôt able to figure out FlightAware or similar APIs\nBase64 Images - LLM got stuck trying to copy GIANT chunks of base64 images, when it could have just pointed to the the files.\n\nLesson: No-code tools are great for prototyping standard UI patterns. They struggle with complex game logic and API integrations that require env vars.",
    "crumbs": [
      "projects",
      "Panda Tracker: A Vibecoding Case Study"
    ]
  },
  {
    "objectID": "projects/panda_tracker.html#phase-2-port-to-cursor",
    "href": "projects/panda_tracker.html#phase-2-port-to-cursor",
    "title": "Panda Tracker: A Vibecoding Case Study",
    "section": "Phase 2: Port to Cursor",
    "text": "Phase 2: Port to Cursor\n\nIntegrating the Dino Game\nThe Chrome Dino game source is ~2500 lines. Expecting any LLM to write this from scratch is unrealistic.\nApproach: 1. Found the extracted Dino game source code online 2. Asked Cursor to integrate it by copying the code 3. Problem: Cursor stalled ‚Äî too much to copy at once 4. Fix: Manually added the file, then asked Cursor to wire it up\nThe game is embedded as an iframe:\n// components/dino-game.tsx\n&lt;iframe\n  src=\"/dino-game.html\"\n  className=\"absolute inset-0 w-full h-full border-0\"\n  title=\"Dino Game\"\n/&gt;\nLesson: When copying large existing codebases, be smarter and use LLMs to integrate, not to transcribe.",
    "crumbs": [
      "projects",
      "Panda Tracker: A Vibecoding Case Study"
    ]
  },
  {
    "objectID": "projects/panda_tracker.html#phase-3-flight-api-integration",
    "href": "projects/panda_tracker.html#phase-3-flight-api-integration",
    "title": "Panda Tracker: A Vibecoding Case Study",
    "section": "Phase 3: Flight API Integration",
    "text": "Phase 3: Flight API Integration\n\nThe Magic: API Docs as Context\nFlightAware‚Äôs AeroAPI was the choice. Here‚Äôs what made it work:\n\nLinked Cursor to the API docs ‚Äî FlightAware has clean documentation\nCursor read the docs and implemented the integration in minutes\nGot the API key, added to .env.local\n\nKey implementation details: - Rate limiting with exponential backoff - Date filtering in origin timezone\n- Status mapping (scheduled ‚Üí delayed ‚Üí en_route ‚Üí arrived) - Caching to keep (free) api calls to a minimum\nLesson: LLMs excel at API integrations when given good documentation. Point them to the docs, not just the problem.",
    "crumbs": [
      "projects",
      "Panda Tracker: A Vibecoding Case Study"
    ]
  },
  {
    "objectID": "projects/panda_tracker.html#phase-4-custom-sprites-the-fun-part",
    "href": "projects/panda_tracker.html#phase-4-custom-sprites-the-fun-part",
    "title": "Panda Tracker: A Vibecoding Case Study",
    "section": "Phase 4: Custom Sprites (The Fun Part)",
    "text": "Phase 4: Custom Sprites (The Fun Part)\nWanted to replace the T-Rex with a panda. This got interesting.\n\nAttempt 1: Cursor-generated SVG\n\nAsked Cursor to generate sprite SVGs\nResult: Wrong proportions, didn‚Äôt match game requirements\n\n\n\nAttempt 2: AI Image Generation\n\nAsked Cursor to analyze the game code and give a sprite spec\nTook that spec to Google‚Äôs Nano Banana Pro\nRequested a panda sprite sheet matching the spec\nGot a perfect sprite sheet!\n\n\n\n\nSprites\n\n\n\n\nAttempt 3: Processing the Sprite Sheet\n\nCursor can‚Äôt ‚Äúsee‚Äù images accurately for cropping\nAsked Cursor to create a processing script and output cropping positions as variables instead\nManually calculated the actual pixel positions\nUpdated crop positions:\n\n# The sprite positions I had to manually calculate\nsprites_approx = [\n    (45, 260, 215, 480),    # Frame 0: Standing (for jumping)\n    (265, 260, 420, 480),   # Frame 1: Idle (for waiting/blinking)\n    (490, 260, 670, 480),   # Frame 2: Running 1\n    (700, 260, 876, 480),   # Frame 3: Running 2  \n    (935, 260, 1085, 480),  # Frame 4: Running 3\n    (1110, 260, 1360, 480), # Frame 5: Crashed\n]\nLesson: For image work, use LLMs to generate specs and code scaffolding, but expect to manually tune coordinates. You can minimize the manual steps by scripting as much as possible.",
    "crumbs": [
      "projects",
      "Panda Tracker: A Vibecoding Case Study"
    ]
  },
  {
    "objectID": "projects/panda_tracker.html#phase-5-deploy",
    "href": "projects/panda_tracker.html#phase-5-deploy",
    "title": "Panda Tracker: A Vibecoding Case Study",
    "section": "Phase 5: Deploy",
    "text": "Phase 5: Deploy\nEasy stuff now. ### Vercel Setup 1. Connect GitHub repo 2. Critical: Don‚Äôt commit .env.local 3. Add environment variables in Vercel dashboard: - FLIGHTAWARE_API_KEY 4. Deploy üöÄ\n\n\n\nVercel",
    "crumbs": [
      "projects",
      "Panda Tracker: A Vibecoding Case Study"
    ]
  },
  {
    "objectID": "projects/panda_tracker.html#links",
    "href": "projects/panda_tracker.html#links",
    "title": "Panda Tracker: A Vibecoding Case Study",
    "section": "Links",
    "text": "Links\n\nLive Site: panda-tracker.ofalabs.com\nGitHub: https://github.com/ashantanu/panda-tracker",
    "crumbs": [
      "projects",
      "Panda Tracker: A Vibecoding Case Study"
    ]
  },
  {
    "objectID": "projects/panda_tracker.html#key-takeaways",
    "href": "projects/panda_tracker.html#key-takeaways",
    "title": "Panda Tracker: A Vibecoding Case Study",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\n\n\nPhase\nTool\nWhat Worked\nWhat Didn‚Äôt\n\n\n\n\nPrototype\nLovable/Replit\nUI scaffolding\nComplex logic, APIs\n\n\nDev\nCursor\nAPI integration, wiring\nLarge file copying\n\n\nSprites\nNano Banana\nImage generation\n-\n\n\nSprites\nCursor + Manual\nSpec generation\nPixel-perfect cropping\n\n\nDeploy\nVercel\nSeamless\n-\n\n\n\nThe Vibecoding Workflow:\n\nStart with no-code for fast iteration\nPort to Cursor when you hit limitations\nPoint LLMs at documentation, not just problems\nKnow when to step in manually\nKeep API keys out of git, set them in deploy settings",
    "crumbs": [
      "projects",
      "Panda Tracker: A Vibecoding Case Study"
    ]
  },
  {
    "objectID": "figma-plugin.html",
    "href": "figma-plugin.html",
    "title": "Getting Started",
    "section": "",
    "text": "https://www.figma.com/plugin-docs/plugin-quickstart-guide/\nNext, install TypeScript using the command:\nnpm install -g typescript\nif you get a permission error try the command with sudo.\nFinally, in the directory of your plugin, get the latest type definitions for the plugin API by running:\nnpm install --save-dev @figma/plugin-typings\nUsing TypeScript requires a compiler to convert TypeScript (code.ts) into JavaScript (code.js) for the browser to run.\nWe recommend writing TypeScript code using Visual Studio code:\n\nOpen project directory in Visual Studio Code.\nCompile TypeScript to JavaScript: Run the ‚ÄúTerminal &gt; Run Build Task‚Ä¶‚Äù menu item, then select ‚Äúnpm: watch‚Äù. You will have to do this again every time you reopen Visual Studio Code.\n\n\nHot reloading Figma provides the option to hot reload your plugin to speed up the development process. As you edit the plugin code and rebuild, the plugin will automatically restart with the latest changes. If turned off, you will need to manually restart the plugin.\nplugins &gt; Development &gt;hot reload plugins",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html",
    "href": "Interview-prep/python_basics.html",
    "title": "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "",
    "text": "In the world of software engineering, fundamentals are not optional‚Äîthey‚Äôre foundational. Whether you‚Äôre preparing for a technical interview or just brushing up on core concepts, revisiting the essentials can be a career-defining move. This post is a curated walkthrough of CS fundamentals, Pythonic tools, and best practices‚Äîdesigned to be both a refresher and a launchpad.",
    "crumbs": [
      "Interview-prep",
      "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html#the-interview-mindset",
    "href": "Interview-prep/python_basics.html#the-interview-mindset",
    "title": "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "üìå The Interview Mindset:",
    "text": "üìå The Interview Mindset:\nBefore diving into syntax or data structures, let‚Äôs talk about approach. In interviews, it‚Äôs not just about solving the problem‚Äîit‚Äôs about how you solve it.\n\n‚úÖ Coding Best Practices to Keep in Mind:\n\nClarify the problem: Don‚Äôt assume. Ask about edge cases, constraints, and input types.\nThink out loud: Your thought process is as important as your final answer.\nStart with brute force: Then optimize. Show your evolution.\nWrite readable code: Use meaningful variable names and modular functions.\nTest manually: Walk through your code with sample inputs.\nExplain trade-offs: Time vs.¬†space, readability vs.¬†performance.",
    "crumbs": [
      "Interview-prep",
      "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html#design-patterns",
    "href": "Interview-prep/python_basics.html#design-patterns",
    "title": "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "üß± Design Patterns:",
    "text": "üß± Design Patterns:\nDesign patterns are reusable solutions to common software design problems. They‚Äôre not code templates‚Äîthey‚Äôre mental models.\n\nCommon Patterns to Know:\n\nSingleton: Ensures a class has only one instance.\nFactory: Creates objects without exposing instantiation logic.\nObserver: One-to-many dependency between objects.\nStrategy: Encapsulates interchangeable behaviors.\nDecorator: Adds behavior to objects dynamically.\n\nKnowing when and why to use these patterns can elevate your design discussions in interviews.",
    "crumbs": [
      "Interview-prep",
      "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html#python-helper-functions",
    "href": "Interview-prep/python_basics.html#python-helper-functions",
    "title": "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "üêç Python Helper Functions:",
    "text": "üêç Python Helper Functions:\nPython‚Äôs standard library is a goldmine for solving problems efficiently. Here‚Äôs a categorized list of built-in functions and idioms that often come in handy:\n\nüî§ String Utilities\ns.isdigit(), s.isalpha(), s.lower(), s.strip(), s[::-1], s.split(), s.count()\n\n\nüìã List Operations\nsorted(), sum(), min(), max(), list.append(), list.pop(), list.count()\n\n\nüìö Dictionary & Set Operations\ndict.get(), dict.items(), set.add(), set.intersection(), set.difference()\n\n\nüî¢ Math & Conversion\nabs(), round(), pow(), bin(), hex(), int('101', 2), float('3.14')\n\n\nüîÅ Functional Tools\nmap(), filter(), zip(), enumerate(), any(), all()\n\n\nüî£ ASCII & Unicode\nord('A')  # 65\nchr(65)   # 'A'",
    "crumbs": [
      "Interview-prep",
      "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html#data-structures-in-python-stack-queue-heap",
    "href": "Interview-prep/python_basics.html#data-structures-in-python-stack-queue-heap",
    "title": "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "üß∞ Data Structures in Python: Stack, Queue, Heap",
    "text": "üß∞ Data Structures in Python: Stack, Queue, Heap\n\nü•û Stack (LIFO)\nstack = []\nstack.append(x)\nstack.pop()\nOr use collections.deque for better performance:\nfrom collections import deque\nstack = deque()\nstack.append(x)\nstack.pop()\n\n\nüì¨ Queue (FIFO)\nfrom collections import deque\nqueue = deque()\nqueue.append(x)\nqueue.popleft()\nOr use queue.Queue for thread-safe operations.\n\n\n‚è´ Priority Queue (Min-Heap)\nimport heapq\nheap = []\nheapq.heappush(heap, x)\nheapq.heappop(heap)\nTo simulate a max-heap:\nheapq.heappush(heap, -x)\n-max(heapq.heappop(heap))",
    "crumbs": [
      "Interview-prep",
      "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html#deque-vs-heapq-know-the-difference",
    "href": "Interview-prep/python_basics.html#deque-vs-heapq-know-the-difference",
    "title": "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "üîÅ deque vs heapq: Know the Difference",
    "text": "üîÅ deque vs heapq: Know the Difference\n\n\n\nFeature\ndeque\nheapq\n\n\n\n\nType\nDouble-ended queue\nBinary heap (min-heap)\n\n\nInsert/Remove\nO(1) at both ends\nO(log n)\n\n\nUse Case\nQueues, stacks\nPriority queues, heaps",
    "crumbs": [
      "Interview-prep",
      "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html#time-complexity-reference-table",
    "href": "Interview-prep/python_basics.html#time-complexity-reference-table",
    "title": "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "üßÆ Time Complexity Reference Table",
    "text": "üßÆ Time Complexity Reference Table\nHere‚Äôs a quick cheat sheet for the time complexity of key operations in each structure:\n\n\n\n\n\n\n\n\n\n\nOperation\nlist\ndeque\nheapq (min-heap)\nset / dict\n\n\n\n\nAppend (end)\nO(1) amortized\nO(1)\nO(log n)\n‚Äî\n\n\nPop (end)\nO(1)\nO(1)\nO(log n)\n‚Äî\n\n\nPop (start)\nO(n)\nO(1) (popleft)\n‚Äî\n‚Äî\n\n\nInsert (start)\nO(n)\nO(1) (appendleft)\n‚Äî\n‚Äî\n\n\nSearch\nO(n)\nO(n)\nO(n)\nO(1)\n\n\nMembership Test\nO(n)\nO(n)\nO(n)\nO(1)\n\n\nPush to Heap\n‚Äî\n‚Äî\nO(log n)\n‚Äî\n\n\nPop from Heap\n‚Äî\n‚Äî\nO(log n)\n‚Äî\n\n\nPeek Min (heap[0])\n‚Äî\n‚Äî\nO(1)\n‚Äî\n\n\nGet by Key\n‚Äî\n‚Äî\n‚Äî\nO(1) (dict)",
    "crumbs": [
      "Interview-prep",
      "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "Interview-prep/python_basics.html#final-thoughts",
    "href": "Interview-prep/python_basics.html#final-thoughts",
    "title": "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns",
    "section": "üß† Final Thoughts",
    "text": "üß† Final Thoughts\nMastery isn‚Äôt about memorizing APIs‚Äîit‚Äôs about understanding patterns, recognizing trade-offs, and writing code that communicates intent. Whether you‚Äôre preparing for interviews or just refining your craft, these tools and techniques will serve you well.\n\nIf you found this useful, I‚Äôd love to hear what you‚Äôre brushing up on‚Äîor what you‚Äôd like to see next. You can also check out my other technical deep dives here.\nHappy coding. üöÄ",
    "crumbs": [
      "Interview-prep",
      "üß† A Practical Guide to CS Fundamentals, Python Tricks & Interview-Ready Patterns"
    ]
  },
  {
    "objectID": "index.html#origin-story",
    "href": "index.html#origin-story",
    "title": "Chaos Garden",
    "section": "Origin Story",
    "text": "Origin Story\nIn a digital galaxy not so far away, I have put up little digital spaces over the internet. Be it social media or poorly designed websites like this. I interact with each space in different capacities but always try to make things interesting. This is the latest in my attempt to put my overthinking brain with my tech skills into a production(?) tech blog that might help out others!",
    "crumbs": [
      "Chaos Garden"
    ]
  },
  {
    "objectID": "index.html#whats-here",
    "href": "index.html#whats-here",
    "title": "Chaos Garden",
    "section": "What‚Äôs Here?",
    "text": "What‚Äôs Here?\nI don‚Äôt know yet lol. This is still a fresh clay pot in making, I am hoping to give it shape over the next few weeks. Hopefully, it evolves into a coherent story or becomes the namesake. win-win :)",
    "crumbs": [
      "Chaos Garden"
    ]
  },
  {
    "objectID": "index.html#whats-a-space",
    "href": "index.html#whats-a-space",
    "title": "Chaos Garden",
    "section": "What‚Äôs a SPACE?",
    "text": "What‚Äôs a SPACE?\nEvery little place where I can drop a bit-o-information or notes or just about anything. A folder in a drawer, a pocket in a purse, a shelf in a closet, or a web page on the internet. Just WAY more unorganised.",
    "crumbs": [
      "Chaos Garden"
    ]
  },
  {
    "objectID": "index.html#what-do-i-expect",
    "href": "index.html#what-do-i-expect",
    "title": "Chaos Garden",
    "section": "What do I Expect?",
    "text": "What do I Expect?\nFEEDBACK! I‚Äôd love feedback. I have grown to understand the internet is full of wonderful supportive people. This is my beacon to the community of these fellow netizens. \"HELLO WORLD\"",
    "crumbs": [
      "Chaos Garden"
    ]
  },
  {
    "objectID": "ML/llm_output_parser.html",
    "href": "ML/llm_output_parser.html",
    "title": "Intro to LangChain Output Parsers",
    "section": "",
    "text": "If you have fiddled around with ChatGPT or LangChain yet, you would have realised how difficult it is to get the outcome we expect everytime. For whatever reason, we might expect a list, or a table and it would output a lot of text that we never asked for.\nLet‚Äôs follow an example to see what is the issue we usually face with LLMs and how we can use Output Parsers to resolve it. But first, some setup!",
    "crumbs": [
      "ML",
      "Intro to LangChain Output Parsers"
    ]
  },
  {
    "objectID": "ML/llm_output_parser.html#bonus",
    "href": "ML/llm_output_parser.html#bonus",
    "title": "Intro to LangChain Output Parsers",
    "section": "Bonus",
    "text": "Bonus\n\n\n\ncan‚Äôt end this without a midjourney pikachu encounter. prompt: ‚Äúpikachu in legend of zelda, cgi, high quality render‚Äù",
    "crumbs": [
      "ML",
      "Intro to LangChain Output Parsers"
    ]
  },
  {
    "objectID": "ML/old_blogs.html",
    "href": "ML/old_blogs.html",
    "title": "Older Blog Posts",
    "section": "",
    "text": "Hi GitHub CoPilot! -Chatting with the AI pair programmer\nDoodling AI : Man is to Computer Programmer as Woman is to Homemaker?\nDoodling AI: CrowS-Pairs Challenge\nNLP Paper Notes\nGenerative Network Notes\nAnnotated Papers",
    "crumbs": [
      "ML",
      "Older Blog Posts"
    ]
  },
  {
    "objectID": "ML/ml_tweet_graveyard.html",
    "href": "ML/ml_tweet_graveyard.html",
    "title": "ML Tweet Graveyard",
    "section": "",
    "text": "Andrej Karpathy beatifully covers why llama.cpp works.\n\n\n\"How is LLaMa.cpp possible?\" great post by @finbarrtimbers https://t.co/yF43inlY87llama.cpp surprised many people (myself included) with how quickly you can run large LLMs on small computers, e.g.¬†7B runs @ ~16 tok/s on a MacBook. Wait don't you need supercomputers to work‚Ä¶ pic.twitter.com/EIp9iPkZ6x\n\n‚Äî Andrej Karpathy (@karpathy) August 15, 2023",
    "crumbs": [
      "ML",
      "ML Tweet Graveyard"
    ]
  },
  {
    "objectID": "ML/intro.html",
    "href": "ML/intro.html",
    "title": "ML Space",
    "section": "",
    "text": "A random collection of ML related resources that I keep collecting like trinkets frm my travels.\nLLMs have taken the world by storm. They are close to what AI has been promising for the last 50 years. The time is ripe to start learning about them. This repo is a collection of resources that I found useful.\nYou can find notes on my readings here: ML Notes",
    "crumbs": [
      "ML",
      "ML Space"
    ]
  },
  {
    "objectID": "ML/intro.html#techincal-resources",
    "href": "ML/intro.html#techincal-resources",
    "title": "ML Space",
    "section": "Techincal Resources",
    "text": "Techincal Resources\n\nAwesome LLM: always a big fan of awesome github repos. this one is quentessential for LLMs",
    "crumbs": [
      "ML",
      "ML Space"
    ]
  },
  {
    "objectID": "ML/intro.html#ai-tools",
    "href": "ML/intro.html#ai-tools",
    "title": "ML Space",
    "section": "AI Tools",
    "text": "AI Tools\n\nEssentials\n\nGithub Copilot is TOP tier coding ESSENTIAL ‚ú®\nChat GPT duh!",
    "crumbs": [
      "ML",
      "ML Space"
    ]
  }
]